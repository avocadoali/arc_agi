2024-12-20 09:25:29 PM EST: run from json
2024-12-20 09:25:29 PM EST: process challenges w limit
2024-12-20 09:25:29 PM EST: [00d62c1b] running root node with 5 attempts.
2024-12-20 09:25:29 PM EST: strarting attempt run
2024-12-20 09:25:31 PM EST: Creating vllm client done 
2024-12-20 09:25:31 PM EST: [Q795NB5P] calling vllm model
2024-12-20 09:25:31 PM EST: Other vllm error: Error code: 400 - {'object': 'error', 'message': "This model's maximum context length is 4096 tokens. However, you requested 20374 tokens in the messages, Please reduce the length of the messages.", 'type': 'BadRequestError', 'param': None, 'code': 400}, retrying in 0 seconds (0/200)...
