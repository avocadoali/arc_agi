2025-01-06 11:38:27,905 - DEBUG - run from json
2025-01-06 11:38:27,970 - DEBUG - [1736159907.9702353] starting run from json
2025-01-06 11:38:28,077 - DEBUG - process challenges w limit
2025-01-06 11:38:28,077 - DEBUG - [017c7c7b] running root node with 5 attempts.
2025-01-06 11:38:28,077 - DEBUG - strarting attempt run
2025-01-06 11:38:29,726 - DEBUG - Creating vllm client done 
2025-01-06 11:38:29,726 - DEBUG - [JEEBQZ6K] calling vllm model
2025-01-06 11:38:45,382 - DEBUG - [JEEBQZ6K] took 15655.53, cache_creation_input_tokens=0 cache_read_input_tokens=0 input_tokens=6177 output_tokens=734, cost_cents=2.9541
2025-01-06 11:38:45,382 - DEBUG - [ZZD6RLPI] calling vllm model
2025-01-06 11:38:45,389 - DEBUG - [0OJTVBMA] calling vllm model
2025-01-06 11:38:45,395 - DEBUG - [TGNHC70J] calling vllm model
2025-01-06 11:38:45,402 - DEBUG - [B4488VP0] calling vllm model
2025-01-06 11:39:11,248 - DEBUG - [0OJTVBMA] took 25859.18, cache_creation_input_tokens=0 cache_read_input_tokens=0 input_tokens=6177 output_tokens=544, cost_cents=2.6691
2025-01-06 11:39:37,649 - DEBUG - [B4488VP0] took 52247.09, cache_creation_input_tokens=0 cache_read_input_tokens=0 input_tokens=6177 output_tokens=918, cost_cents=3.2301
2025-01-06 11:39:45,139 - DEBUG - [ZZD6RLPI] took 59756.64, cache_creation_input_tokens=0 cache_read_input_tokens=0 input_tokens=6177 output_tokens=1161, cost_cents=3.5946
2025-01-06 11:39:52,004 - DEBUG - [TGNHC70J] took 66608.94, cache_creation_input_tokens=0 cache_read_input_tokens=0 input_tokens=6177 output_tokens=1246, cost_cents=3.7221
2025-01-06 11:39:52,005 - DEBUG - Got the n_messages
2025-01-06 11:39:52,343 - DEBUG - [017c7c7b] grids took 0.3383028507232666 secs
2025-01-06 11:39:52,343 - DEBUG - startgin eval attempts
2025-01-06 11:39:52,343 - DEBUG - eval the attempts
2025-01-06 11:39:52,344 - DEBUG - eval
**{'challenge_id': '017c7c7b', 'total_runs': 5, 'total_correct': 0, 'avg_train_accuracy': 0.2, 'avg_test_accuracy': 0.4, 'total_cost': 16.17, 'prompt_config': RootPromptConfig(base_prompt=<Prompt.REASONING: 'REASONING'>, use_ascii=True, use_array=True, use_image=True, use_examples=True, use_diffs=True, use_images=True, returns_python=True), 'llm_config': LLMConfig(model=<Model.qwen2_5_72b_instruct: 'Qwen/Qwen2.5-72B-Instruct-GPTQ-Int4'>, temperature=0.95), 'time_took_ms': 84266.08}**

2025-01-06 11:39:52,344 - DEBUG - [017c7c7b] eval took 0.0003466606140136719 secs
2025-01-06 11:39:52,344 - DEBUG - try for perfect attemtps
2025-01-06 11:39:52,344 - DEBUG - run fixes
2025-01-06 11:39:52,344 - DEBUG - [017c7c7b] running fix node with 1 total attempts.
2025-01-06 11:39:52,346 - DEBUG - [017c7c7b] Processing fix attempts:   0%|          | 0/1 [00:00<?, ?it/s]
2025-01-06 11:39:52,471 - DEBUG - Creating vllm client done 
2025-01-06 11:39:52,472 - DEBUG - [8CZ4LB6T] calling vllm model
2025-01-06 11:40:53,853 - DEBUG - [8CZ4LB6T] took 61380.85, cache_creation_input_tokens=0 cache_read_input_tokens=0 input_tokens=10877 output_tokens=1232, cost_cents=5.1111
2025-01-06 11:40:53,853 - DEBUG - Got the n_messages
2025-01-06 11:40:54,052 - DEBUG - [017c7c7b] grids took 0.19926929473876953 secs
2025-01-06 11:40:54,053 - DEBUG - [017c7c7b] Processing fix attempts: 100%|##########| 1/1 [01:01<00:00, 61.71s/it]
2025-01-06 11:40:54,053 - DEBUG - 
2025-01-06 11:40:54,053 - DEBUG - [017c7c7b] Processing fix attempts: 100%|##########| 1/1 [01:01<00:00, 61.71s/it]
2025-01-06 11:40:54,053 - DEBUG - 

2025-01-06 11:40:54,053 - DEBUG - eval the attempts
2025-01-06 11:40:54,053 - DEBUG - eval
**{'challenge_id': '017c7c7b', 'total_runs': 1, 'total_correct': 0, 'avg_train_accuracy': 0.3333333333333333, 'avg_test_accuracy': 1.0, 'total_cost': 5.1111, 'prompt_config': FixPromptConfig(base_prompt=<Prompt.REASONING: 'REASONING'>, use_ascii=True, use_array=True, use_image=True, use_fix_reasoning_tags=True, use_fix_fail_line=True, use_typical_issue_text=True, include_diffs=True, returns_python=True), 'llm_config': LLMConfig(model=<Model.qwen2_5_72b_instruct: 'Qwen/Qwen2.5-72B-Instruct-GPTQ-Int4'>, temperature=0.95), 'time_took_ms': 61709.28}**

2025-01-06 11:40:54,054 - DEBUG - [017c7c7b] eval took 0.0007612705230712891 secs
2025-01-06 11:40:54,054 - DEBUG - ALL ATTEMPTS LEN: 1
2025-01-06 11:40:54,054 - DEBUG - checkt attempts again
2025-01-06 11:40:54,054 - DEBUG - [017c7c7b] DONE: n attempts: 6, total cost cents: 21.281100000000002
2025-01-06 11:40:54,054 - DEBUG - [017c7c7b] solution
**{'challenge_id': '017c7c7b', 'challenge': Challenge(id='017c7c7b', train=[Example(input=[[0, 1, 0], [1, 1, 0], [0, 1, 0], [0, 1, 1], [0, 1, 0], [1, 1, 0]], output=[[0, 2, 0], [2, 2, 0], [0, 2, 0], [0, 2, 2], [0, 2, 0], [2, 2, 0], [0, 2, 0], [0, 2, 2], [0, 2, 0]]), Example(input=[[0, 1, 0], [1, 0, 1], [0, 1, 0], [1, 0, 1], [0, 1, 0], [1, 0, 1]], output=[[0, 2, 0], [2, 0, 2], [0, 2, 0], [2, 0, 2], [0, 2, 0], [2, 0, 2], [0, 2, 0], [2, 0, 2], [0, 2, 0]]), Example(input=[[0, 1, 0], [1, 1, 0], [0, 1, 0], [0, 1, 0], [1, 1, 0], [0, 1, 0]], output=[[0, 2, 0], [2, 2, 0], [0, 2, 0], [0, 2, 0], [2, 2, 0], [0, 2, 0], [0, 2, 0], [2, 2, 0], [0, 2, 0]])], test=[Example(input=[[1, 1, 1], [0, 1, 0], [0, 1, 0], [1, 1, 1], [0, 1, 0], [0, 1, 0]], output=[[2, 2, 2], [0, 2, 0], [0, 2, 0], [2, 2, 2], [0, 2, 0], [0, 2, 0], [2, 2, 2], [0, 2, 0], [0, 2, 0]])]), 'solution_d': [ChallengeSolution(attempt_1=[[2, 2, 2], [0, 2, 0], [0, 2, 0], [2, 2, 2], [0, 2, 0], [0, 2, 0], [2, 2, 2], [0, 2, 0], [0, 2, 0]], attempt_2=[[2, 2, 2], [0, 2, 0], [2, 2, 2], [0, 2, 0], [2, 2, 2], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0]])]}**

2025-01-06 11:40:54,057 - DEBUG - [017c7c7b] took 145.98 secs to solve and write
2025-01-06 11:40:54,057 - DEBUG - FINAL: took 146.09 secs to run 1 challenges
2025-01-06 11:40:54,057 - DEBUG - eval solutions
