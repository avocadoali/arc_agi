2025-01-06 11:35:53,384 - DEBUG - run from json
2025-01-06 11:35:53,384 - DEBUG - [1736159753.3843172] starting run from json
2025-01-06 11:35:53,493 - DEBUG - process challenges w limit
2025-01-06 11:35:53,493 - DEBUG - [017c7c7b] running root node with 5 attempts.
2025-01-06 11:35:53,493 - DEBUG - strarting attempt run
2025-01-06 11:35:58,622 - DEBUG - Creating vllm client done 
2025-01-06 11:35:58,623 - DEBUG - [IS19Y12O] calling vllm model
2025-01-06 11:36:07,744 - DEBUG - [IS19Y12O] took 9121.04, cache_creation_input_tokens=0 cache_read_input_tokens=0 input_tokens=6177 output_tokens=446, cost_cents=2.5221
2025-01-06 11:36:07,744 - DEBUG - [AY6QVRZ1] calling vllm model
2025-01-06 11:36:07,751 - DEBUG - [33LBKJVJ] calling vllm model
2025-01-06 11:36:07,758 - DEBUG - [9AVXVZVJ] calling vllm model
2025-01-06 11:36:07,764 - DEBUG - [2732W71I] calling vllm model
2025-01-06 11:36:27,522 - DEBUG - [33LBKJVJ] took 19771.15, cache_creation_input_tokens=0 cache_read_input_tokens=0 input_tokens=6177 output_tokens=607, cost_cents=2.7636
2025-01-06 11:36:33,385 - DEBUG - [AY6QVRZ1] took 25641.29, cache_creation_input_tokens=0 cache_read_input_tokens=0 input_tokens=6177 output_tokens=912, cost_cents=3.2211
2025-01-06 11:36:33,818 - DEBUG - [9AVXVZVJ] took 26059.82, cache_creation_input_tokens=0 cache_read_input_tokens=0 input_tokens=6177 output_tokens=911, cost_cents=3.2196
2025-01-06 11:36:35,884 - DEBUG - [2732W71I] took 28119.49, cache_creation_input_tokens=0 cache_read_input_tokens=0 input_tokens=6177 output_tokens=1032, cost_cents=3.4011
2025-01-06 11:36:35,884 - DEBUG - Got the n_messages
2025-01-06 11:36:36,273 - DEBUG - [017c7c7b] grids took 0.3891298770904541 secs
2025-01-06 11:36:36,274 - DEBUG - startgin eval attempts
2025-01-06 11:36:36,274 - DEBUG - eval the attempts
2025-01-06 11:36:36,274 - DEBUG - eval
**{'challenge_id': '017c7c7b', 'total_runs': 5, 'total_correct': 0, 'avg_train_accuracy': 0.06666666666666667, 'avg_test_accuracy': 0.2, 'total_cost': 15.1275, 'prompt_config': RootPromptConfig(base_prompt=<Prompt.REASONING: 'REASONING'>, use_ascii=True, use_array=True, use_image=True, use_examples=True, use_diffs=True, use_images=True, returns_python=True), 'llm_config': LLMConfig(model=<Model.qwen2_5_72b_instruct: 'Qwen/Qwen2.5-72B-Instruct-GPTQ-Int4'>, temperature=0.95), 'time_took_ms': 42780.32}**

2025-01-06 11:36:36,274 - DEBUG - [017c7c7b] eval took 0.00034046173095703125 secs
2025-01-06 11:36:36,274 - DEBUG - try for perfect attemtps
2025-01-06 11:36:36,274 - DEBUG - run fixes
2025-01-06 11:36:36,274 - DEBUG - [017c7c7b] running fix node with 1 total attempts.
2025-01-06 11:36:36,277 - DEBUG - [017c7c7b] Processing fix attempts:   0%|          | 0/1 [00:00<?, ?it/s]
2025-01-06 11:36:36,281 - DEBUG - Error with is correct: operands could not be broadcast together with shapes (9,3) (12,3) 
2025-01-06 11:36:36,281 - DEBUG - Error with is correct: operands could not be broadcast together with shapes (9,3) (12,3) 
2025-01-06 11:36:36,281 - DEBUG - Error with is correct: operands could not be broadcast together with shapes (9,3) (12,3) 
2025-01-06 11:36:36,403 - DEBUG - Creating vllm client done 
2025-01-06 11:36:36,403 - DEBUG - [J2UNEVF7] calling vllm model
2025-01-06 11:37:21,579 - DEBUG - [J2UNEVF7] took 45175.97, cache_creation_input_tokens=0 cache_read_input_tokens=0 input_tokens=10336 output_tokens=941, cost_cents=4.5123
2025-01-06 11:37:21,580 - DEBUG - Got the n_messages
2025-01-06 11:37:21,804 - DEBUG - [017c7c7b] grids took 0.22436928749084473 secs
2025-01-06 11:37:21,805 - DEBUG - [017c7c7b] Processing fix attempts: 100%|##########| 1/1 [00:45<00:00, 45.53s/it]
2025-01-06 11:37:21,805 - DEBUG - 
2025-01-06 11:37:21,805 - DEBUG - [017c7c7b] Processing fix attempts: 100%|##########| 1/1 [00:45<00:00, 45.53s/it]
2025-01-06 11:37:21,805 - DEBUG - 

2025-01-06 11:37:21,805 - DEBUG - eval the attempts
2025-01-06 11:37:21,805 - DEBUG - eval
**{'challenge_id': '017c7c7b', 'total_runs': 1, 'total_correct': 0, 'avg_train_accuracy': 0.3333333333333333, 'avg_test_accuracy': 1.0, 'total_cost': 4.5123, 'prompt_config': FixPromptConfig(base_prompt=<Prompt.REASONING: 'REASONING'>, use_ascii=True, use_array=True, use_image=True, use_fix_reasoning_tags=True, use_fix_fail_line=True, use_typical_issue_text=True, include_diffs=True, returns_python=True), 'llm_config': LLMConfig(model=<Model.qwen2_5_72b_instruct: 'Qwen/Qwen2.5-72B-Instruct-GPTQ-Int4'>, temperature=0.95), 'time_took_ms': 45530.85}**

2025-01-06 11:37:21,806 - DEBUG - [017c7c7b] eval took 0.0006983280181884766 secs
2025-01-06 11:37:21,806 - DEBUG - ALL ATTEMPTS LEN: 1
2025-01-06 11:37:21,806 - DEBUG - checkt attempts again
2025-01-06 11:37:21,806 - DEBUG - [017c7c7b] DONE: n attempts: 6, total cost cents: 19.6398
2025-01-06 11:37:21,806 - DEBUG - [017c7c7b] solution
**{'challenge_id': '017c7c7b', 'challenge': Challenge(id='017c7c7b', train=[Example(input=[[0, 1, 0], [1, 1, 0], [0, 1, 0], [0, 1, 1], [0, 1, 0], [1, 1, 0]], output=[[0, 2, 0], [2, 2, 0], [0, 2, 0], [0, 2, 2], [0, 2, 0], [2, 2, 0], [0, 2, 0], [0, 2, 2], [0, 2, 0]]), Example(input=[[0, 1, 0], [1, 0, 1], [0, 1, 0], [1, 0, 1], [0, 1, 0], [1, 0, 1]], output=[[0, 2, 0], [2, 0, 2], [0, 2, 0], [2, 0, 2], [0, 2, 0], [2, 0, 2], [0, 2, 0], [2, 0, 2], [0, 2, 0]]), Example(input=[[0, 1, 0], [1, 1, 0], [0, 1, 0], [0, 1, 0], [1, 1, 0], [0, 1, 0]], output=[[0, 2, 0], [2, 2, 0], [0, 2, 0], [0, 2, 0], [2, 2, 0], [0, 2, 0], [0, 2, 0], [2, 2, 0], [0, 2, 0]])], test=[Example(input=[[1, 1, 1], [0, 1, 0], [0, 1, 0], [1, 1, 1], [0, 1, 0], [0, 1, 0]], output=[[2, 2, 2], [0, 2, 0], [0, 2, 0], [2, 2, 2], [0, 2, 0], [0, 2, 0], [2, 2, 2], [0, 2, 0], [0, 2, 0]])]), 'solution_d': [ChallengeSolution(attempt_1=[[2, 2, 2], [0, 2, 0], [0, 2, 0], [2, 2, 2], [0, 2, 0], [0, 2, 0], [2, 2, 2], [0, 2, 0], [0, 2, 0]], attempt_2=[[2, 2, 2], [2, 2, 2], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [2, 2, 2], [2, 2, 2], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0]])]}**

2025-01-06 11:37:21,932 - DEBUG - [017c7c7b] took 88.44 secs to solve and write
2025-01-06 11:37:21,933 - DEBUG - FINAL: took 88.55 secs to run 1 challenges
2025-01-06 11:37:21,933 - DEBUG - eval solutions
